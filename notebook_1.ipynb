{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GOOGLE COLLAB LINK=https://colab.research.google.com/drive/16pkEkSkoHGbmOuRg6hgS4L_N0RRepYZF?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt3-NvpdyPAF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNoXaVnzyfwh"
      },
      "outputs": [],
      "source": [
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"âœ“ Libraries imported successfully\")\n",
        "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oqoMvvkzyWm"
      },
      "outputs": [],
      "source": [
        "print(\"\\nðŸ“‚ Loading datasets...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adySW8eYygkh"
      },
      "outputs": [],
      "source": [
        "sentiment_df = pd.read_csv('/content/fear_greed_index.csv')\n",
        "trades_df = pd.read_csv('/content/historical_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qpWIa55z2Ia"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA EXPLORATION\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nðŸ“Š SENTIMENT DATA OVERVIEW:\")\n",
        "print(sentiment_df.head())\n",
        "print(\"\\nColumns:\", sentiment_df.columns.tolist())\n",
        "print(\"\\nData types:\\n\", sentiment_df.dtypes)\n",
        "print(\"\\nMissing values:\\n\", sentiment_df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gTiuOkS2Tds"
      },
      "outputs": [],
      "source": [
        "print(\"\\nðŸ“ˆ TRADER DATA STATISTICS:\")\n",
        "print(trades_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OvOIWcs2e57"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Parse dates\n",
        "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
        "trades_df['Timestamp'] = pd.to_datetime(trades_df['Timestamp'])\n",
        "\n",
        "# Extract date from timestamp for merging\n",
        "trades_df['date'] = trades_df['Timestamp'].dt.date\n",
        "sentiment_df['date'] = sentiment_df['date'].dt.date\n",
        "\n",
        "# Handle missing values in critical columns\n",
        "print(\"\\nðŸ”§ Handling missing values...\")\n",
        "initial_rows = len(trades_df)\n",
        "trades_df = trades_df.dropna(subset=['closedPnL'])\n",
        "\n",
        "# Fill missing leverage with median\n",
        "if trades_df['leverage'].isnull().sum() > 0:\n",
        "    median_leverage = trades_df['leverage'].median()\n",
        "    trades_df['leverage'].fillna(median_leverage, inplace=True)\n",
        "\n",
        "print(f\"Rows after cleaning: {len(trades_df)} (removed {initial_rows - len(trades_df)} rows)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OvOIwcs2e57"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Parse dates\n",
        "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
        "trades_df['Timestamp'] = pd.to_datetime(trades_df['Timestamp'], unit='s')\n",
        "\n",
        "# Extract date from timestamp for merging\n",
        "trades_df['date'] = trades_df['Timestamp'].dt.date\n",
        "sentiment_df['date'] = sentiment_df['date'].dt.date\n",
        "\n",
        "# Handle missing values in critical columns\n",
        "print(\"\\nðŸ”§ Handling missing values...\")\n",
        "initial_rows = len(trades_df)\n",
        "trades_df = trades_df.dropna(subset=['Closed PnL'])\n",
        "\n",
        "print(f\"Rows after cleaning: {len(trades_df)} (removed {initial_rows - len(trades_df)} rows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c353b338"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(df, column, multiplier=1.5):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - multiplier * IQR\n",
        "    upper_bound = Q3 + multiplier * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "print(\"\\nðŸ”§ Removing outliers...\")\n",
        "before_outlier_removal = len(trades_df)\n",
        "trades_df = remove_outliers_iqr(trades_df, 'Closed PnL', multiplier=3)\n",
        "\n",
        "print(f\"Rows after outlier removal: {len(trades_df)} (removed {before_outlier_removal - len(trades_df)} outliers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1enFjSw49kA"
      },
      "outputs": [],
      "source": [
        "print(\"\\nðŸ”— Merging sentiment and trader data...\")\n",
        "merged_df = trades_df.merge(\n",
        "    sentiment_df[['date', 'classification']],\n",
        "    on='date',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Merged dataset: {merged_df.shape[0]} rows\")\n",
        "print(f\"Rows with sentiment data: {merged_df['classification'].notna().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7tLIw5B2jdz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create additional features\n",
        "print(\"\\nðŸŽ¯ Feature engineering...\")\n",
        "\n",
        "# Profitable trade indicator\n",
        "merged_df['is_profitable'] = (merged_df['Closed PnL'] > 0).astype(int)\n",
        "\n",
        "# Absolute PnL\n",
        "merged_df['abs_pnl'] = merged_df['Closed PnL'].abs()\n",
        "\n",
        "# Trade value\n",
        "merged_df['trade_value'] = merged_df['Size Tokens'] * merged_df['Execution Price']\n",
        "\n",
        "# Hour of day (for temporal analysis)\n",
        "merged_df['hour'] = pd.to_datetime(merged_df['Timestamp']).dt.hour\n",
        "\n",
        "# Day of week\n",
        "merged_df['day_of_week'] = pd.to_datetime(merged_df['Timestamp']).dt.dayofweek\n",
        "\n",
        "print(\"âœ“ Feature engineering complete\")\n",
        "\n",
        "# Save processed data\n",
        "output_dir = 'csv_files'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "merged_df.to_csv(f'{output_dir}/processed_data.csv', index=False)\n",
        "print(f\"\\nðŸ’¾ Processed data saved to {output_dir}/processed_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooctJXDs4lqf"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SENTIMENT ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sentiment distribution\n",
        "sentiment_counts = sentiment_df['classification'].value_counts()\n",
        "sentiment_pct = sentiment_df['classification'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\nðŸ“Š Sentiment Distribution:\")\n",
        "for sentiment, count in sentiment_counts.items():\n",
        "    pct = sentiment_pct[sentiment]\n",
        "    print(f\"  {sentiment}: {count} days ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBh7y0sN6URc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Pie chart\n",
        "axes[0].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
        "            colors=sns.color_palette(\"husl\", len(sentiment_counts)), startangle=90)\n",
        "axes[0].set_title('Market Sentiment Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Time series\n",
        "axes[1].plot(sentiment_df['date'], sentiment_df['value'], linewidth=1, alpha=0.7)\n",
        "axes[1].set_title('Sentiment Value Over Time', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Date')\n",
        "axes[1].set_ylabel('Sentiment Value')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Create the 'outputs' directory if it doesn't exist\n",
        "output_dir = 'outputs'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "plt.savefig(f'{output_dir}/sentiment_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Sentiment visualizations saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLngrq-I6gC9"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRADER BEHAVIOR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Overall metrics\n",
        "print(\"\\nðŸ“Š OVERALL TRADING METRICS:\")\n",
        "print(f\"Total Trades: {len(merged_df):,}\")\n",
        "print(f\"Unique Traders: {merged_df['Account'].nunique():,}\")\n",
        "print(f\"Total PnL: ${merged_df['Closed PnL'].sum():,.2f}\")\n",
        "print(f\"Average PnL per Trade: ${merged_df['Closed PnL'].mean():,.2f}\")\n",
        "print(f\"Median PnL per Trade: ${merged_df['Closed PnL'].median():,.2f}\")\n",
        "print(f\"Win Rate: {(merged_df['is_profitable'].mean() * 100):.2f}%\")\n",
        "print(f\"Average Trade Size: ${merged_df['trade_value'].mean():,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFZ1Tnee6vV7"
      },
      "outputs": [],
      "source": [
        "print(\"\\nðŸ“Š METRICS BY SENTIMENT:\")\n",
        "sentiment_metrics = merged_df.groupby('classification').agg({\n",
        "    'Closed PnL': ['sum', 'mean', 'median', 'std'],\n",
        "    'trade_value': ['sum', 'mean'],\n",
        "    'is_profitable': 'mean',\n",
        "    'Account': 'nunique'\n",
        "}).round(2)\n",
        "\n",
        "display(sentiment_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n2fWGmM658y"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STATISTICAL ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Prepare data for testing\n",
        "fear_data = merged_df[merged_df['classification'] == 'Fear']\n",
        "greed_data = merged_df[merged_df['classification'] == 'Greed']\n",
        "\n",
        "# T-test: PnL comparison\n",
        "print(\"\\nðŸ”¬ T-TEST: PnL in Fear vs Greed\")\n",
        "t_stat_pnl, p_value_pnl = stats.ttest_ind(\n",
        "    fear_data['Closed PnL'].dropna(),\n",
        "    greed_data['Closed PnL'].dropna()\n",
        ")\n",
        "print(f\"T-statistic: {t_stat_pnl:.4f}\")\n",
        "print(f\"P-value: {p_value_pnl:.4f}\")\n",
        "print(f\"Result: {'Significant' if p_value_pnl < 0.05 else 'Not significant'} difference at Î±=0.05\")\n",
        "\n",
        "# Chi-square test: Side preference by sentiment\n",
        "print(\"\\nðŸ”¬ CHI-SQUARE TEST: Side Preference by Sentiment\")\n",
        "contingency_table = pd.crosstab(merged_df['Side'], merged_df['classification'])\n",
        "print(\"\\nContingency Table:\")\n",
        "display(contingency_table)\n",
        "\n",
        "chi2, p_value_chi, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value_chi:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"Result: {'Significant' if p_value_chi < 0.05 else 'Not significant'} association at Î±=0.05\")\n",
        "\n",
        "# Correlation analysis\n",
        "print(\"\\nðŸ”¬ CORRELATION ANALYSIS:\")\n",
        "correlation_features = ['Closed PnL', 'trade_value', 'Size Tokens']\n",
        "correlation_matrix = merged_df[correlation_features].corr()\n",
        "display(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2c2c785"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRADES DATA PREPROCESSING (CONSOLIDATED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load the original trades data again to ensure correct starting point\n",
        "trades_df = pd.read_csv('/content/historical_data.csv')\n",
        "\n",
        "# Parse dates with unit='ms'\n",
        "trades_df['Timestamp'] = pd.to_datetime(trades_df['Timestamp'], unit='ms')\n",
        "\n",
        "# Extract date from timestamp for merging\n",
        "trades_df['date'] = trades_df['Timestamp'].dt.date\n",
        "\n",
        "# Handle missing values in critical columns\n",
        "print(\"\\nðŸ”§ Handling missing values...\")\n",
        "initial_rows = len(trades_df)\n",
        "trades_df = trades_df.dropna(subset=['Closed PnL'])\n",
        "print(f\"Rows after cleaning: {len(trades_df)} (removed {initial_rows - len(trades_df)} rows)\")\n",
        "\n",
        "# Remove outliers\n",
        "print(\"\\nðŸ”§ Removing outliers...\")\n",
        "before_outlier_removal = len(trades_df)\n",
        "trades_df = remove_outliers_iqr(trades_df, 'Closed PnL', multiplier=3)\n",
        "print(f\"Rows after outlier removal: {len(trades_df)} (removed {before_outlier_removal - len(trades_df)} outliers)\")\n",
        "\n",
        "print(\"\\nâœ“ Trades data preprocessing complete\")\n",
        "\n",
        "print(\"\\nDate range in trades_df after consolidated preprocessing:\")\n",
        "if not trades_df.empty:\n",
        "    print(f\"Date Range: {trades_df['date'].min()} to {trades_df['date'].max()}\")\n",
        "    print(\"Sample Unique Dates:\")\n",
        "    display(trades_df['date'].unique()[:10])\n",
        "else:\n",
        "    print(\"trades_df is empty after preprocessing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f95dfc32"
      },
      "outputs": [],
      "source": [
        "print(\"Unique dates in trades_df after preprocessing:\")\n",
        "display(trades_df['date'].unique())\n",
        "\n",
        "print(\"\\nUnique dates in sentiment_df after preprocessing:\")\n",
        "display(sentiment_df['date'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bZNfGY77Ple"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Visualization 1: PnL by Sentiment\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Bar plot: Total PnL\n",
        "pnl_by_sentiment = merged_df.groupby('classification')['Closed PnL'].sum()\n",
        "colors = ['#ff6b6b' if x == 'Fear' else '#51cf66' for x in pnl_by_sentiment.index]\n",
        "axes[0].bar(pnl_by_sentiment.index, pnl_by_sentiment.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title('Total PnL by Market Sentiment', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Total PnL ($)')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "for i, v in enumerate(pnl_by_sentiment.values):\n",
        "    axes[0].text(i, v, f'${v:,.0f}', ha='center', va='bottom' if v > 0 else 'top', fontweight='bold')\n",
        "\n",
        "# Box plot: PnL distribution\n",
        "merged_df.boxplot(column='Closed PnL', by='classification', ax=axes[1], patch_artist=True)\n",
        "axes[1].set_title('PnL Distribution by Sentiment', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Market Sentiment')\n",
        "axes[1].set_ylabel('Closed PnL ($)')\n",
        "plt.suptitle('')  # Remove default title\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/pnl_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ PnL analysis saved\")\n",
        "\n",
        "# Visualization 2: Correlation Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Trading Metrics', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Correlation matrix saved\")\n",
        "\n",
        "# Visualization 3: Trading Volume by Sentiment\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Total volume\n",
        "volume_by_sentiment = merged_df.groupby('classification')['trade_value'].sum()\n",
        "axes[0, 0].bar(volume_by_sentiment.index, volume_by_sentiment.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_title('Total Trading Volume by Sentiment', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Volume ($)')\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Number of trades\n",
        "trades_by_sentiment = merged_df.groupby('classification').size()\n",
        "axes[0, 1].bar(trades_by_sentiment.index, trades_by_sentiment.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_title('Number of Trades by Sentiment', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Win rate\n",
        "win_rate_by_sentiment = merged_df.groupby('classification')['is_profitable'].mean() * 100\n",
        "axes[1, 0].bar(win_rate_by_sentiment.index, win_rate_by_sentiment.values, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_title('Win Rate by Sentiment', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Win Rate (%)')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "axes[1, 0].axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50% baseline')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Side preference\n",
        "side_sentiment = pd.crosstab(merged_df['classification'], merged_df['Side'], normalize='index') * 100\n",
        "side_sentiment.plot(kind='bar', ax=axes[1, 1], color=['#e74c3c', '#3498db'], alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_title('Position Side Preference by Sentiment', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Percentage (%)')\n",
        "axes[1, 1].set_xlabel('Market Sentiment')\n",
        "axes[1, 1].legend(title='Side')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/trader_behavior.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Trader behavior analysis saved\")\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 9: ADVANCED INSIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ADVANCED INSIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Trader segmentation\n",
        "print(\"\\nðŸ‘¥ TRADER SEGMENTATION:\")\n",
        "trader_performance = merged_df.groupby('Account').agg({\n",
        "    'Closed PnL': 'sum',\n",
        "    'Account': 'count'  # number of trades\n",
        "}).rename(columns={'Account': 'num_trades'})\n",
        "\n",
        "trader_performance['avg_pnl'] = trader_performance['Closed PnL'] / trader_performance['num_trades']\n",
        "\n",
        "# Classify traders\n",
        "trader_performance['category'] = pd.cut(\n",
        "    trader_performance['Closed PnL'],\n",
        "    bins=[-np.inf, -1000, 1000, np.inf],\n",
        "    labels=['Loser', 'Neutral', 'Winner']\n",
        ")\n",
        "\n",
        "print(trader_performance['category'].value_counts())\n",
        "\n",
        "# Profitable trader analysis by sentiment\n",
        "print(\"\\nðŸ’° TOP TRADERS BY SENTIMENT:\")\n",
        "top_fear_traders = merged_df[merged_df['classification'] == 'Fear'].groupby('Account')['Closed PnL'].sum().nlargest(5)\n",
        "top_greed_traders = merged_df[merged_df['classification'] == 'Greed'].groupby('Account')['Closed PnL'].sum().nlargest(5)\n",
        "\n",
        "print(\"\\nTop 5 Traders During FEAR:\")\n",
        "print(top_fear_traders)\n",
        "\n",
        "print(\"\\nTop 5 Traders During GREED:\")\n",
        "print(top_greed_traders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faTUIyiP8Yvd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY FINDINGS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "findings = f\"\"\"\n",
        "1. SENTIMENT DISTRIBUTION:\n",
        "   - Fear days: {sentiment_pct.get('Fear', 0):.1f}%\n",
        "   - Greed days: {sentiment_pct.get('Greed', 0):.1f}%\n",
        "   - Extreme Fear days: {sentiment_pct.get('Extreme Fear', 0):.1f}%\n",
        "   - Extreme Greed days: {sentiment_pct.get('Extreme Greed', 0):.1f}%\n",
        "   - Neutral days: {sentiment_pct.get('Neutral', 0):.1f}%\n",
        "\n",
        "2. PROFITABILITY BY SENTIMENT:\n",
        "   - Average PnL (Fear): ${fear_data['Closed PnL'].mean():.2f}\n",
        "   - Average PnL (Greed): ${greed_data['Closed PnL'].mean():.2f}\n",
        "   - Statistical significance (Fear vs Greed PnL): {'Yes (p<0.05)' if p_value_pnl < 0.05 else 'No (pâ‰¥0.05)'}\n",
        "\n",
        "3. TRADING VOLUME:\n",
        "   - Total volume (Fear): ${fear_data['trade_value'].sum():,.0f}\n",
        "   - Total volume (Greed): ${greed_data['trade_value'].sum():,.0f}\n",
        "\n",
        "4. WIN RATE:\n",
        "   - Win rate (Fear): {fear_data['is_profitable'].mean() * 100:.2f}%\n",
        "   - Win rate (Greed): {greed_data['is_profitable'].mean() * 100:.2f}%\n",
        "\n",
        "5. POSITION BIAS:\n",
        "   - Side preference is {'significantly' if p_value_chi < 0.05 else 'not significantly'} associated with sentiment (Chi-square p-value: {p_value_chi:.4f})\n",
        "\"\"\"\n",
        "\n",
        "print(findings)\n",
        "\n",
        "# Save summary to file\n",
        "with open('csv_files/analysis_summary.txt', 'w') as f:\n",
        "    f.write(findings)\n",
        "\n",
        "print(\"\\nâœ“ Analysis summary saved to csv_files/analysis_summary.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bmn6Q5z8zNs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
